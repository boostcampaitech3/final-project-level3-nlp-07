# 최종 프로젝트 랩업리포트

Tags: 회고록

# 1. 프로젝트 개요

## 문제 정의

- 문제: 배달앱의 고객 리뷰에는 사장님이 답글을 달 수 있는 기능이 있으나, 모든 업장 사장님이 이 기능을 쓰진 않음
- 원인: 모든 리뷰에 사장님이 일일이 장문의 답글을 타이핑 하기엔 작업 시간이 많이 들기 때문에 기피하는 경향이 있음
- 해결책: 주어진 고객 리뷰에 대응하는 적절한 답변을 자동 완성하여 제시하면, 작업 시간이 줄어들 것이며, 사장님들이 좀 더 자신있게 답글을 달 수 있도록 도와줄 수 있을 것이다.

## 개발 목표

- 한국어 생성 모델을 활용하여 배달앱 고객 리뷰에 대응하는 사장님 답글을 생성하여 제안하는 서비스 만들기.
- 부스트캠프 기간 동안 학습했던 데이터 수집, 모델링, 서빙을 모두 체험해볼 수 있는 프로젝트를 경험해보기.
- 실제 비지니스에서 사용되는 데이터를 직접 수집하고 사용하면서 실무와 가까운 프로젝트를 경험해보기.

# 2. 프로젝트 팀 구성 및 역할

- 타임라인

![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled.png)

- 역할
    - 김준재: KoBART finetuning, 리펙토링, KcELECTRA 텍스트 감정분석 모델 활용
    - 김현아: 데이터 전/후처리, 텍스트 유사도 분석, 프로토타입 제작
    - 배현진: 데이터 크롤링, 모델링(GPT2)
    - 이강민: 크롤링 코드 작성, 데이터 EDA, 텍스트 유사도 분석(glove, SBERT)
    - 최성원: 데이터 크롤링 수행, 데이터 EDA, 프로토타입 제작(streamlit)

# 3. 프로젝트 수행 절차 및 방법

## 데이터셋

### 크롤링

- Selenium을 이용하여 요기요 웹페이지를 크롤링
- 서울 전체 지하철역 주소 기준으로 크롤링
    
    ![4B69B5E0-97E6-4E76-978E-CE0ACF3B50DE.jpeg](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/4B69B5E0-97E6-4E76-978E-CE0ACF3B50DE.jpeg)
    
- 모든 업종의 리뷰 데이터를 수집하기엔 너무 방대하였기에, 요기요의 모든 업종 중에 ‘카페/디저트’ 부분만 크롤링
- 사장님 답글이 있는 리뷰만 크롤링

### EDA

- 고객 리뷰 + 사장 답글 (약 25만 데이터)
- 길이 분포
    - 고객 리뷰
        
        ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%201.png)
        
        ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%202.png)
        
    - 사장 답글
        
        ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%203.png)
        
        ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%204.png)
        
    - 길이 분포의 통계를 바탕으로 고객 리뷰와 사장 답글이 적절한 길이인 경우만 사용
        - 고객 리뷰: 15 초과, 100 미만
        - 사장 답글: 50 초과, 200 미만

### 전처리

- 유사도
    - 기반 아이디어
        - 단순히 사장님 답글을 학습하는 것이 아닌 고객 리뷰에 맞춰 생성하는 것을 목표로 하였다. 따라서, 고객 리뷰와 사장님 답글간의 유사도가 필요했다.
    - Glove
        - 한국어 위키백과, KorQuAD, 네이버 영화 말뭉치 등으로 학습된 glove를 사용
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%205.png)
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%206.png)
            
        - glove의 경우 명사를 추출하고 유사도를 측정하기 때문에 0이 대략 3만개 발생
    - Sentence-BERT
        - SBERT의 finetuning 방식인 STS(Semantic Textual Similarity) 문제는 두 문장으로부터 의미적 유사성을 구한다. 해당 방식이 우리가 생각하는 유사도와 비슷하다고 생각하여 사용
        - multi-lingual SBERT 중 가장 성능이 좋은 paraphrase-multilingual-MiniLM-L12-v2 를 사용
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%207.png)
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%208.png)
            
        - 최종 유사도 분포를 이용하여 glove는 0을 제외한 분포에서 0.4 이상, Sentence-BERT는 전체 분포에서 0.4 이상의 값을 보이는 데이터만 남도록 전처리

- 감정분석
    - 가설: “고객 리뷰 글과 사장 답글 사이에는 모종의 유사성이 존재할 것이며, 이러한 유사한 패턴 중 검출 가능한 것 중 하나가 감정일 것이다.”
    - 감정분석 모델의 훈련용으로 서울대 KOTE 데이터셋을 이용([https://github.com/searle-j/KOTE](https://github.com/searle-j/KOTE))
        - KOTE 데이터셋은 인터넷 댓글을 기반으로 하기 때문에, 문장의 분위기가 배달 앱 리뷰와 유사할 것이라 판단
        - KOTE로 사전학습 된 모델(KcElectra)을 사용
    - 정해진 threshold(0.4) 이상의 확률을 가지는 감정 라벨에 대해 각 문장 쌍의 감정 유사성을 판단.
        - 실험 결과, 하나 이상의 공통적인 감정라벨을 가지는 경우가 약 95% 가량 있는 것으로 확인.
    - 추후 활용하고자 감정 라벨을 데이터셋에 추가
- 개인정보 마스킹
    - 고객이름 마스킹(aa**님, aa**고객님, aa** 님, Aa**님, AA**님)
    - 상호명 마스킹 (스타벅스-공덕점, 스타벅스 공덕점, 스타벅스)
    - 위치 & 기관 마스킹 (00점, 00재단)
    - 전화번호 마스킹
        - 전화번호(010-삼5오-129), 인스타 계정 (@ad_3)
        - 이메일(dsf@gmail.com), 홈페이지(defc.insta.com)

## 모델

### KoGPT-2

- 모델 소개
    - transformer의 디코더로 구성된 모델
    - 각 토큰을 순차적으로 예측하고, 이전에 예측된 토큰을 다음 단계의 입력으로 사용하는 Auto-Regressive 모델
- finetuning
    - 손님의 리뷰를 보고, 모델은 그 리뷰에 대응하는 답글을 생성해주어야 하기때문에 손님 리뷰와 사장님 답글을 함께 합쳐서 입력
    - 입력 구조
        - input: 손님리뷰 <review> 사장님답글 / target: 사장님답글
    - implementation
        - SKT/KoGPT2([https://github.com/SKT-AI/KoGPT2](https://github.com/SKT-AI/KoGPT2))를 이용
        - max length 300(손님답글 200 + 사장답글 100)
        - batch = 16, lr = 3e-5, weight decay = 0.001

### KoBART

- 모델 소개
    - Transformer의 Encoder와 Decoder 구조를 모두 가진 LM
    - 고객 리뷰 글 만을 input으로 넣어 encoding 된 데이터를 기반으로 decoder가 알맞은 답글을 생성 할 수 있을 것이라 생각하여 채택
- finetuning
    - 입력 구조
        - input: 별점 + 손님 리뷰 / target: 사장님 답글
    - implementation
        - KoBART(https://github.com/SKT-AI/KoBART)를 이용
        - Max Length: Input(256), Target(128)
        - batch = 32, lr = 3e-5, weight decay = 0.001

## Product Serving

- Train
    - Huggingface
    - PyTorch Lightning
- Inference & Generation
    - Greedy
    - Sampling
    - Beam-search
- Demo
    - Streamlit
    - FastAPI
- 모델링 아키텍처
    - 셀레니움으로 크롤링하여 수집한 데이터를 각종 EDA를 통해 정제
    - BART와 GPT-2 학습
    - 결과를 분석해 데이터셋의 미흡한 점을 개선하여 다시 학습시켜 결과를 얻는 사이클

![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%209.png)

- 전체 서비스 아키텍처
    
    ![스크린샷 2022-06-13 오후 5.38.13.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-13_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_5.38.13.png)
    

# 4. 프로젝트 수행 결과

## 시연

<메인 페이지>

![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%2010.png)

<사장 답글 생성>

![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%2011.png)

## 결과

- ROUGE
    - 다양한 Text Generation task에 있어 가장 많이 사용되는 metric 중 하나
    - ROUGE-L: LCS를 사용해 단어의 longest matching sequence를 계산
    
    | 모델 + 토큰 생성 방식 | rouge-l(f) |
    | --- | --- |
    | KoBART - samling | 0.000006449 |
    | KoBART - beam | 0.000010963 |
    | KoGPT2 - sampling | 0.000012017 |
    | KoGPT2 - beam | 0.000009345 |
    - ROUGE의 경우, 같은 단어를 사용하는 경우에 점수가 높게 나오게 된다. 하지만 우리 서비스에서는 정해진 답이 있는 것이 아니라 고객 리뷰 데이터에 대해 단어가 달라도 연관성이 높고 응집력 있는 사장 답글을 만들어 내는 것이 목표
        - 따라서 기존에 텍스트 생성 task에서 가장 많이 사용되던 ROUGE 점수를 대체할 수 있는 metric을 고안, automatic metric으로는 감정분석과 유사도 분석, human evaluation으로는 두가지 기준을 두어 평가를 진행
- 유사도 분석
    - 데이터 전처리에 활용하던 glove와 Sentence BERT를 활용하여 모델 성능 측정
    
    | 모델 + 토큰 생성 방식 | Glove |
    | --- | --- |
    | KoBART - samling | 0.7008 |
    | KoBART - beam | 0.6973 |
    | KoGPT2 - sampling | 0.6469 |
    | KoGPT2 - beam | 0.6441 |
    | 원본(고객 - 사장) | 0.6839 |
    
    | 모델 + 토큰 생성 방식 | SBERT |
    | --- | --- |
    | KoBART - samling | 0.5954 |
    | KoBART - beam | 0.5610 |
    | KoGPT2 - sampling | 0.5693 |
    | KoGPT2 - beam | 0.5926 |
    | 원본(고객 - 사장) | 0.6311 |
    - 학습 데이터셋이 0.4 이상인 경우만 뽑아 활용하였는데, 모델들이 생성한 답글도 어느정도 수준 이상의 유사도를 보임
- 감정 분석
    - 감정 유사도를 계산하는 정량적 방법
        - emotion_score(공감 수치) = (customer & manager) / (customer | manager)
    
    | 모델 + 토큰 생성 방식 | 공감수치 |
    | --- | --- |
    | KoBART - samling | 0.6250 |
    | KoBART - beam | 0.6256 |
    | KoGPT2 - sampling | 0.6148 |
    | KoGPT2 - beam | 0.6225 |
    | 원본(고객 - 사장) | 0.6433 |
- 사용자 평가
    - 두가지 기준에 대해 사용자 평가 진행 (5인)
        - 유창성: 문법이나 사용되는 단어가 적절한지
        - 연관성: 고객리뷰와 생성된 사장 답글이 내용상 얼마나 연관되어 있는지
    - 각 모델별로 100개의 고객 답글에 대해 예측한 답글로 평가
    - 의견의 일치도를 평가하기 위해 Fleiss Kappa와 단순 hard-voting을 통해 결과를 도출
        - Generation Task이기 때문에 사람마다 유창성과 연관성의 척도가 다르며, 그렇기 때문에 fleiss-kappa의 경우 점수가 매우 낮게 나옴
        - Hard-Voting을 통한 유창성과 연관성의 경우 beam search를 통해 토큰을 생성한 경우 가장 점수가 높았음

| 모델 + 토큰 생성 방식 | 유창성 | 연관성 |
| --- | --- | --- |
| KoBART - sampling | 0.12 | 0.018 |
| KoBART - beam | -0.033 | 0.164 |
| KoGPT2 - sampling | 0.393 | 0.078 |
| KoGPT2 - beam | -0.063 | -0.042 |

<Fleiss-Kappa>

| 모델 + 토큰 생성 방식 | 유창성 | 연관성 |
| --- | --- | --- |
| KoBART - sampling | 53 | 49 |
| KoBART - beam | 84 | 64 |
| KoGPT2 - sampling | 80 | 63 |
| KoGPT2 - beam | 98 | 66 |

<Hard-Voting>

# 5. 자체 평가 의견

## 문제점

- Generation 시간이 오래 걸림
    - 한 리뷰 당 답글 생성까지 3~5초가 소요되기 때문에, 실시간 서비스에 다소 무리가 있어보임
- 컴플레인 대응
    - 리뷰는 부정적이지만 사장답글은 이를 고려하지 못하는 경우가 발생
        - ex) 고객 리뷰: 양추가해도 너무적어요. ㅜㅜ 야채도적어요 ㅜㅜ 맛은괜찮는데조금짜요 배달은너무느려요 ㅋㅋㅋ 흠..,
            - 예측 답글: 저는 정말맛있게드셔주시니감사드려용^^ 더 노력하는 #@상호명# 되겠습니다
- 답글 퀄리티
    - 상관이 없는 메뉴를 언급하는 경우
        - ex) 고객 리뷰: 마시멜로 도넛은 생각보다 그냥 그러네요~ 소금우유 도넛은 빵이 쫄깃쫄깃 해서 맛있게 잘먹었습니다.
            - 예측 답글: 역시 디저트하면 잠봉뵈르죠:D
    - 어투나 사용하는 단어가 서비스에 적합하지 않는 경우
        - ex) 고객 리뷰: 25일 주문인데.. 유통기한임25일인건 좀 심한듯해요.. 직접고르면 이건 고르지 않았을듯요..
            - 예측 답글: 저희는 매장도 친절하세요~~^^ ;; 다른 제품에도 잘 어울려서 고객님이 선택하신겁니다. 맛있게 드셔주셔서 감사합니다. 건강히 살펴용😁
    - 사실 관계 여부를 알 수 없는 경우(시간, 계절, 사진 포함 유무)
        - ex) 고객 리뷰: 배달도 빠르고 쉐이크도 맛있어요. 포방도 잘되있어서 세지 않았네요
            - 예측 답글: 저희를 믿고 주문해주셔서 너무 감사합니다~^^ 맛있게 잘 드셨길 바래요. 오늘 하루도 따스한 봄날 되시길 바랍니다. 진심으로 감사드립니다.

## 시도했으나 안 됐던 것

- KoGPT-2 to huggingface
    - 기존에 가지고 있던 huggingface를 사용한 베이스라인을 사용해 KoGPT2 Review Generation 코드를 작성했으나 학습 속도가 매우 느려 실험을 진행하기에 부적절했음
        - 빠른 시간 내에 결과를 내야했기 때문에 코드를 작성은 했지만 사용하지 못했던 부분이 아쉬움
        - 코드를 정리하며 어떤 부분 때문에 속도가 느려진 것인지 살펴 볼 예정
- NER로 위치 & 기관 Entity 마스킹
    - Pororo 라이브러리의 NER로 위치 및 기관 Entity 마스킹 처리를 하려고 했으나, 1분에 10개 NER을 수행하는 데 총 데이터 양이 20만개라 처리속도가 너무 느려 진행하기 부적절
        - 처리 결과 일부를 확인 및 참고하여 마스킹
- 유사도로 TF-IDF 사용
    - TF-IDF로 고객 리뷰와 사장 답글의 유사도를 분석하려고 했으나 해당 문장간의 TF-IDF 값이 0인 값이 너무 많아 사용하지 못함

## 시도해볼 점

- Inference 시간이 오래 걸리는 문제 해결
    - 모델 경량화 고려
    - 입력으로 들어오면 미리 DB에 저장
    - 모델은 서버에서 준비가 완료되어 있고, 사장님에게 입력만 받아서 API로 통신하는 방식
- 컴플레인 대응 강화
    - 별점을 이용, 부정적인 리뷰 데이터셋을 따로 분할해 부정 리뷰에 대한 모델을 새로 학습
- 리뷰 퀄리티 개선
    - 주문 메뉴, 리뷰 감정, 사진유무 등 리뷰를 작성하는데 필요한 정보를 Input에 추가
    - Prefix로 ‘사장 답글 생성해 줘' 와 같이 모델에 정확한 명령을 줘보기
- 평가 Metric 고안, 개선
    - 유창성 관련 Metric 필요
        - 유사도 평가, 감정분석 모두 연관성과 관련된 Metric
    - 사용자 평가
        - 다양한 사람들의 의견이 필요
        - 현재는 유창성과 연관성 밖에 없지만, 정확한 비교를 위해서는 다양한 평가 지표가 필요

# 6. 개인 회고

## 김준재

### 🧭개인 학습 목표

- 생성 모델의 훈련부터 generation까지 혼자 코딩해보기
- Selenium을 통한 웹페이지 크롤링 시도해보기
- Streamlit을 이용한 프로토타입 시연 웹페이지 제작해보기
- Pytorch Lightning과 Huggingface가 혼재된 스타일의 코드를 Huggingface만 사용하는 스타일로 리팩토링 하기
- 텍스트 감정분석 모델을 활용하여 의미있는 작업에 활용하기

### 📖사용한 지식 & 기술

- Pre-trained LM: KoBART, KoGPT2, KcELECTRA
- Metric: Rouge, 공감수치, sBERT 유사도, glove 유사도
- Hyperparameter Tuning: batch size, epoch, learning rate, weight decay
- Web Service: Streamlit, FastAPI
- Dataset: KOTE, Pandas
- ETC: Pytorch, Huggingface, Selenium

### 🧑🏻‍🎓결과 ⇒ 깨달음

- Selenium을 활용하여 서울 지역 내 카페/디저트 업종에 종사하는 요기요 가맹점의 손님 리뷰-사장 답글 조합의 데이터를 약 25만개 획득할 수 있었다.
    - 섬세한 데이터 수집 가이드라인과 코드 로직이 있다면 웹상에서 양질의 NLP 데이터를 손쉽게 획득할 수 있음을 깨달았다.
- 서울대 KOTE 데이터셋으로 finetuning된 KcELECTRA 모델을 활용하여 리뷰 텍스트의 감정을 분석한 결과, 손님 리뷰-사장 답글 간의 감정적 공감대를 발견하여 수치화 할 수 있었다.
    - NLP 모델을 활용하여 새로운 metric을 고안하여 개발 과정에 적용할 수 있음을 깨달았다.
- 생성모델로 많이 사용되는 KoGPT-2 말고도 KoBART를 finetuning 시켜서 이용 해 본 결과, 트렌디한 스타일의 답글을 잘 생성하는 것을 확인 할 수 있었다.
    - 다양한 언어모델들을 활용하여 각 성격별로 어울리는 세부 task를 배정할 수도 있음을 깨달았다.

### 🛠️새롭게 시도한 변화 ⇒ 효과

- 수집한 데이터셋을 python arrow 데이터셋화 하여 학습과 분석에 이용하였다.
    - 학습과 분석 코드의 실행속도가 빨라졌고, 데이터 조작 등에도 pandas보다 더 손쉽게 사용할 수 있어서 일의 능률이 올라갔다.
- 기존 KoBART-summarize 코드의 Pytorch Lightning 활용 부분을 모두 Huggingface 스타일로 치환하여 전체 코드가 Huggingface 기반으로 돌아가도록 리펙토링 하였다.
    - 더 직관성 있는 코드가 만들어진 덕에, 다른 팀원들에게도 더 직관적인 설명을 할 수 있게 되어 협업 효율성이 상승하였다.
- 서울대 KOTE 데이터셋으로 finetuning된 KcELECTRA 모델을 활용하여 리뷰 텍스트의 감정을 분석하고, 이 결과를 기반으로 공감수치라는 새로운 metric을 고안하여 모델 테스트에 이용하였다.
    - 원본 대비 모델이 생성한 사장 답글의 퀄리티를 정량적으로 평가할 수 있었다.

### 🏗️실수 & 한계 ⇒ 개선 방안

- 개발 시간 제한에 쫓겨 언어 모델로 다양한 실험을 하지 못하여 최적의 결과물을 낼 수 없었다.
    - 다음 프로젝트부터 모델 실험을 더 체계적으로 구성하여 실험 효율을 더욱 끌어올릴 것이다.
- KoBART 코드 리펙토링에 성공한 뒤, 같은 방식으로 KoGPT-2 코드도 Huggingface 스타일로 리펙토링을 하려 시도했으나, 만족스런 결과가 나오지 않았다.
    - 인풋과 타겟 구조를 바꿔 절반의 성공을 거뒀으나, 팀원들이 사용하기엔 부적합한 상황이었다. 모델에 대한 이해도를 더 높였어야 했다.

### 🆕다음 프로젝트에서 새롭게 시도해볼 것들

- 즉각적인 개인 실험 기록 관리
- git의 rebase 기능을 활용한 업데이트 로그 가시성 확보
- 논문에 근거한 추론
- 클라우드 베이스 배포

## 김현아

### 나의 역할

- 데이터 전&후처리 (개인정보 마스킹)
- 고객리뷰와 사장답글 간의 유사도 분석
- Human Eval 참여
- 모델 프로토타입 서빙

### 타임라인

- 1주차: 강의 수강
- 2주차: 강의 수강
- 3주차: 데이터 전처리 & 텍스트 유사도 분석
- 4주차: FastAPI와 Streamlit로 프로토타입 제작

### 목표

- ML 프로젝트 1 cycle 경험해보기
- 실제 데이터 전처리 작업해보기
- FastAPI와 Streamlit을 이용하여 모델 프로토타입 시연하기
- GCP에 모델 배포해보기

### 모델 개선 및 깨달은 점

- screen 명령어로 back-ground 작업하는 방법
- Poetry로 의존성 관리하는 방법
- FastAPI와 Streamlit을 동시에 사용하기 위해서는 포트를 달리하여 사용
- GCP 구성요소 및 Docker로 배포하는 전체적인 프로세스
- 고객리뷰와 사장답글 간의 유사도 분석을 통해, SBERT 점수가 낮은 경우에도 고객과 소통하는 사장답글이 다수 존재함을 확인.
    - 반대되는 단어 (눅눅함 <-> 바삭함)나 함축적인 의미 풀이 (매일 먹는다 == 매일 이용한다)를 잘못 예측한다고 판단하는 걸로 분석.
    - 전반적으로 고객리뷰와 사장답글의 단어나 형태가 비슷할 수록 높은 점수를 얻는 것을 확인

### 아쉬운 점

- NER로 위치와 기관 Entity에 해당하는 모든 부분을 자동으로 마스킹 처리를 하려고 했는데, 시간이 너무 오래 걸리는 바람에 수동으로 처리했어야 한 게 아쉽다.
- GCP에 모델 배포를 못해본 게 아쉽다.

## 배현진

- 역할: 데이터 크롤링, 모델링

### 목표

- 공개된 코드가 아니라 직접 모델링 코드 작성하기
- 데이터 크롤링부터 Product Serving까지 AI를 활용한 프로젝트를 협업으로 경험하기

### 타임라인

- 1주차: 데이터 크롤링
- 2주차: GPT-2 베이스라인 구축
- 3주차: 데이터 재 전처리를 위한 결과 분석, 베이스라인 수정 및 실험
- 4주차: 모델 평가

### GPT-2(**Radford** et al., 2019)

- 목표:
    - KoGPT2-summarization([https://github.com/seujung/KoGPT2-summarization](https://github.com/seujung/KoGPT2-summarization))를 참고, huggingface 기반 베이스라인을 수정
    - 유창하고 고객 리뷰에 대응하는 내용을 가진 사장답글을 생성
- 모델: `skt/kogpt2-base-v2`
- 과정:
    - huggingface 기반 베이스라인을 Text Generation task로 변경
    - 다양한 Input 포맷을 이용해 실험 진행
        - 고객리뷰 <review> 사장답글
        - 메뉴 고객리뷰 <review> 사장답글
        - 별점 고객리뷰 <review> 사장답글
    - 모델 평가 진행
- 결과 및 아쉬운 점/보완점
    - pytorch-lightning 기반 참고 코드에 비해 학습 시간이 매우 오래 걸림
        - 동일 데이터와 셋팅으로 학습시 pytorch-lightning 기준 1 epoch 당 20분 미만의 시간이 소요되지만 huggingface 기반 1 epoch 당 1시간 반이 소요됨
            - 답글의 성능을 높이기 위해서는 지속해서 셋팅을 바꿔가며 실험이 필요했지만, 속도가 너무 느린 탓에 결국 최종 결과물에는 pytorch-lightning 기반 학습 모델을 사용했던 것이 아쉬움
        - 다른 팀원의 서버에서는 속도가 빨랐던 것을 감안한다면 서버 자원 문제였던 것 같지만 이를 너무 늦게 알았기 때문에 조치를 취하지 못했던 것도 아쉬움
            - 속도가 비정상적으로 느리다면 코드의 문제가 아니라 환경의 문제일 수도 있다는 것을 알았으며, 앞으로는 코드 뿐만 아니라 서버 환경도 고려해보는게 중요하다는 것을 배움
    - 생성모델의 성능에 대한 편견을 깸
        - 그동안 생성모델을 사용한 경우 특히 유창성 부분에서 성능이 그리 좋지 못했기 때문에 아직 생성 모델은 한계를 가지고 있구나 생각하고 있었음
            - 하지만 task에 적합한 데이터, 적절한 EDA와 마스킹, 전처리를 통해 제대로 input이 들어가니 질적으로 평가했을 때 괜찮은 결과가 나옴
            - 그동안은 NLU task에 관심을 가졌는데 이번 프로젝트를 통해 NLG task에도 관심이 생김
    

### 배운 점

- 직접 Data Loader부터 Model, Trainer까지 원하는 task에 맞춰 커스텀해본 점
    - 부스트캠프를 시작할 때 개인적으로 가장 목표로 했던 부분인데, 마지막 프로젝트에서 해낼 수 있었던 점이 가장 크게 배운 점이라 생각한다. 인공지능 공부를 한 지는 꽤 되었음에도 불구하고 항상 코드에 자신이 없었는데, 그래도 부캠을 통해 코드에 대한 자신감을 키우고 수료할 수 있어서 뿌듯하다.
- 데이터 크롤링부터 Product Serving까지 모든 프로세스를 포함한 인공지능 프로젝트를 협업으로 경험한 점
    - 그동안은 모든 프로젝트를 혼자서, 혹은 많아봤자 두명이서 프로젝트를 진행했었는데 이번에는 데이터 EDA, 전처리, 모델링, Product Serving이 병렬적으로 진행되며 각자 한 일과 결과를 공유하고 전달하며 완성품을 만들어 내는 프로젝트를 경험하며 어떤 방식으로 협업을 해야하는지 배웠다. 결과를 혼자서만 알아보는게 아니라 남들도 알아볼 수 있도록 어떻게 정리해야 하는지를 직접 경험을 통해 배울 수 있었다.

### 아쉬웠던 점

- 체계적인 실험을 하지 못한 점
    - 최대한 모델링 관련해서 실험을 많이 해보고 싶었기에, 팀원들이 데이터 EDA를 진행하는 동안 먼저 모델링을 진행했음에도 불구하고 처음에는 실험 성능이 나오지 않아서, 나중에는 학습 시간이 오래 걸려서 더 다양한 실험을 해보지 못해서 아쉽다. 특히 하이퍼파라미터 튜닝을 해보지 못했던 점이 가장 아쉬운 점으로 남는다.
- 시간 부족으로 인해 초반에 생각해 둔 아이디어를 많이 적용해보지 못한 점
    - Prompt 추가, 모델 구조 변경 등 초반에 피어세션을 통해 나눴던 아이디어도 적용해보지 못했고, 또 결과물을 보며 재 전처리를 하는 과정도 계속 반복했어야 했는데 시간이 없이 이를 많이 돌아보지 못한 점도 아쉬웠다.
    

### 다음에 시도해보고 싶은 것들

- Product Serving 단 구축해보기
    - 이번에는 모델링을 하느라 그 다음 단계를 경험해보지 못했는데, 기회가 된다면 학습한 모델로 간단한 프로토타입까지 만드는 것을 해보고 싶다.
- 모델 경량화
    - 서버의 문제도 있었지만 GPT-2 모델 자체가 크기 때문에 실험 속도가 느렸던 것도 있었다고 생각한다. 실제 서비스단에서 해당 모델을 사용하기 위해서는 속도도 매우 중요한 요소이기 때문에 모델 경량화에 대해서도 공부하고 적용해보고 싶다.
    

## 이강민

### 역할

- 크롤링 코드 작성, 데이터 EDA, 텍스트 유사도 분석(Glove, SBERT)

### 이번 프로젝트 목표

- 데이터 수집, 모델링, 서빙을 모두 체험할 수 있는 프로젝트 경험
- 실제 비지니스에서 사용되는 데이터를 직접 수집하고 사용하면서 실무와 가까운 프로젝트 경험

### 프로젝트에서 시도해본 것과 결과

- 크롤링
    - Selenium을 통한 요기요 웹페이지 크롤링
    - 서울 전체 지하철역 주소 기준으로 크롤링
    - 모든 업종의 리뷰 데이터를 수집하기엔 너무 방대하였기에, 요기요의 모든 업종 중에 ‘카페/디저트’ 부분만 크롤링
    - 총 25만 개 데이터 확보

- 데이터 EDA
    - 길이 분포
        - 고객 리뷰
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%201.png)
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%202.png)
            
        - 사장 답글
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%203.png)
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%204.png)
            
        - 길이 분포의 통계를 바탕으로 고객 리뷰와 사장 답글이 적절한 길이인 경우만 사용
            - 고객 리뷰: 15 초과, 100 미만
            - 사장 답글: 50 초과, 200 미만

- 유사도 분석
    - 단순히 사장님 답글을 학습하는 것이 아닌 고객 리뷰에 맞춰 생성하는 것을 목표로 하였다. 따라서, 고객 리뷰와 사장님 답글간의 유사도가 필요했다.
    - Glove
        - 한국어 위키백과, KorQuAD, 네이버 영화 말뭉치 등으로 학습된 glove를 사용
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%205.png)
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%206.png)
            
        - glove의 경우 명사를 추출하고 유사도를 측정하기 때문에 0이 대략 3만개 발생
    - Sentence-BERT
        - SBERT의 finetuning 방식인 STS(Semantic Textual Similarity) 문제는 두 문장으로부터 의미적 유사성을 구한다. 해당 방식이 우리가 생각하는 유사도와 비슷하다고 생각하여 사용
        - multi-lingual SBERT 중 가장 성능이 좋은 paraphrase-multilingual-MiniLM-L12-v2 를 사용
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%207.png)
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%20%E1%84%85%E1%85%A2%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%E1%84%85%E1%85%B5%E1%84%91%E1%85%A9%E1%84%90%E1%85%B3%20282df0ab44cc45969321a09d888880e3/Untitled%208.png)
            
        - 최종 유사도 분포를 이용하여 glove는 0을 제외한 분포에서 0.4 이상, Sentence-BERT는 전체 분포에서 0.4 이상의 값을 보이는 데이터만 남도록 전처리

## 아쉬웠던 점

- TF-IDF를 적용하지 못한 점
- 동일한 inference 환경 구성
- 데이터 EDA 활용

## 다음에 시도해보고 싶은 것들

- 베이스라인 코드를 좀 더 커스텀하여 우리가 수행하는 task에 적합하게 수정
- 모델의 inference time을 최대한 축소
- 깊은 데이터 EDA를 통해 좀 더 다양한 실험 설계

## 최성원

### 학습 목표

- 최대한 많은 것을 경험해보기
    - end to end라는 말을 표방하고 있는 최종 프로젝트이니만큼, 여러가지를 경험하고 시도해보면서 배경 지식을 넓히고 싶었다.
- 진행되는 일에 대한 이해도 높이기
    - 내가 맡은 부분이 아니더라도 우리 팀 내에서 어떤 프로젝트가 진행되고 있으며, 그것이 어떤 의미를 가지고 어떻게 해결해나가야하는지 알고 있어야 전체적인 퀄리티가 올라간다고 생각했다.
    - product serving의 전체 flow를 이해하면 향후 다른 프로젝트를 진행할 때에도 도움이 될 것 이라고 생각했다.
- 모르는 것이 있으면 팀원들에게 바로 질문하기
    - 이전 대회 시 팀원들에게 질문해가며 문제를 해결하면 좋겠다는 피드백이 있었으니만큼, 이번에는 질문이 있다면 바로 질문하여 일의 진행에 차질이 없도록 해야겠다고 생각했다.

### 한 일

- Data Crawling
    - yogiyo에서 서울지역 카페로 직접 크롤링을 수행하여 dataset을 확보
    - 서초구/강남구/송파구 3구에 대해 크롤링 진행
- EDA
    - 크롤링한 csv의 dataset을 직접 보며 경향성, 특이 데이터의 유무 등을 파악
    - 팀원분께서 한 EDA에 대해서도 나도 비슷한 항목에 대해 직접 평가해보기
- Streamlit (frontend)
    - streamlit을 이용하여 마크다운 형식으로 간단한 prototype 제작
- 하루 두번 이상의 회의를 통한 뇌 적시기, 프로젝트 develop 회의

### [KEEP] : 좋았던 점, 잘한 점

- ‘여러가지를 경험해본다는 목표’에 맞게 streamlit도 사용해보고, 강의 실습과 스페셜 미션을 통해 배포에 사용할 수 있는 여러 tool들을 다뤄볼 수 있어 좋았다.
- 내가 맡지 않은 부분이라도 관심있었던 분야들 (KoBart, KoGPT, 감정분석 등)에 대해 피어세션에서 얘기를 들어볼 수 있어 좋았다.
- dataset부터 serving까지 직접 수행했으니만큼, 어떤 것이 사용자 입장에서 유용하고 좋다고 느낄지, 어떤식으로 develop하면 좋을지에 대한 이야기를 많이 나눌 수 있어 좋았다.
- 이전에 진행했던 대회들에서보다는 문제가 피어세션때까지 해결되지 않으면 바로 팀원들에게 질문했고, 이해가 가지 않아도 질문을 했다. 확실히 이전보다 일이 진척되는 느낌이 들어 좋았다.
- 칸반보드 형식의 노션 페이지를 활용하여 프로젝트 일정 관리가 수월하였다.
- 생활 패턴에 대해서도 어느정도 개선되었다.

### [PROBLEM] : 아쉬웠던 점, 문제점

- 직접 실험 설계를 하고 실험을 하고, 모델링을 통해 다듬는 과정을 하지 않아서 아쉬웠다.
    - v100 서버를 완벽하게 활용해내지 못한 것이 못내 아쉬웠다.
    - 실험 결과를 분석하고, 다음 실험에 적용하는 등의 활동을 많이 하지 못해 아쉬웠다.
- ‘끝까지’ 해내지 못한 것 같아 아쉬웠다.
    - 팀 프로젝트를 할 때, ‘기여’에 대해서 아쉬움을 가지고 있던 나이기에, 이번에도 product serving부분에서 확실하게 기여를 하고 싶었으나, backend-frontend 연결에 대해서는 다른분께서 맡아주셨기에 아쉬운 마음이 들었다.
- 내 힘으로 해결하지 못한 문제들이 존재하였다.
    - 적극적으로 질문하는 것은 좋았으나, 스스로 충분히 고민해보고 한 질문도 있었던 반면, 아닌 질문들도 있었기에 아쉬웠다.
- 여유를 갖지 못하였던 것 같다.
    - 짧은 개발기간에 할 task들이 쌓여있고, 개인적인 일도 있었고, 부캠 막바지에 이것저것 할 일이 많다보니 여러방면으로 바쁘다고 느끼기만 했던 것 같다. 오히려 조급한 마음에 그르친 일들도 있는 것 같아 여유가 중요함을 다시한번 깨달았다.
- 후처리나 시연 등에서 발표시 더 명료하고 효과적으로 전달할 수 있도록 개선하는 과정에 아쉬움이 있었다.
    - 시간 부족이 주 원인이었으나, 마지막의 마지막까지도 몰입하였으면 좋았을 것 같다.

### [TRY] : 다음에 하고 싶은 것들

- 체계적인 실험과 그에 대한 기록
    - 논문을 바탕으로 실험을 설계하고 그것을 체계적으로 기록하는 활동은 이번 부스트캠프 기간동안 부족했다는 생각이 들어 꾸준히 리폿하면서 프로젝트를 진행하고 싶다는 생각이 들었다.
- 부스트캠프가 끝났지만, 부캠 기간 동안 제공되었던 강의들의 기간이 만료되기 전에 복습하며 기초를 다져야겠다는 생각이 들었다.
    - 강의를 다시 보고, 기반 논문들을 구현하는 연습을 하면서 모델링 실력을 키워야겠다.
- 다음 프로젝트 진행시 이번 프로젝트처럼 노션을 적극 활용해야겠다는 생각을 하였다.
    - 체계적이고 장기 계획이 필요한 프로젝트 진행에 큰 도움이 될 것 같다.

### 소감

- 마지막 프로젝트가 끝났다. [TRY] 항목을 적는데, 부스트캠프에서는 앞으로 이것들을 적용할 기회가 더이상 없구나, 라는 생각이 들어서 아쉽기도 하고, 끝났다는게 실감이 났다.
- 하나의 서비스를 개발하기에 긴 시간은 절대 아니었다고 생각한다. 개인적인 아쉬움까지도 끝났다는 생각이 들자 아쉬움보다는 애정으로 변하는 것 같다.
- 여러모로 많은 애를 써주신 팀원들께도 너무 감사했다.